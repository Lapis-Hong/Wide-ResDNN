# Train Configuration

# Train & Test Parameters
train:
  model_dir: model
  model_type: wide_deep
  train_data: data/avazu/train.csv
  dev_data: data/avazu/dev.csv
  test_data:
  batch_size: 1000
  train_epochs: 20
  epochs_per_eval: 1
  keep_train: 0
  num_samples: 7300000
  checkpoint_path:
  skip_lines: 1
  field_delim: ','
  verbose: 0

# Model Parameters
model:
  # wide
  wide_learning_rate: 0.1
  wide_lr_decay: true
  wide_lr_decay_steps: 1000
  wide_lr_decay_rate: 0.95
  wide_l1: 0.5
  wide_l2: 1
  # deep
  hidden_units: [64, 64, 64]
  connect_mode: resnet
  residual_mode: concat

  deep_learning_rate: 0.1
  deep_lr_decay: true
  deep_lr_decay_steps: 1000
  deep_lr_decay_rate: 0.95
  activation_function: tf.nn.relu
  deep_l1: 0.01
  deep_l2: 0.01
  dropout:
  batch_normalization: true

# Saving Parameters (Optional)
runconfig:
  tf_random_seed: 12345
  save_summary_steps: 10000
  save_checkpoints_steps: 100000
  save_checkpoints_secs:
  keep_checkpoint_max: 1
  keep_checkpoint_every_n_hours: 1
  log_step_count_steps: 1000

# Distributed Parameters
distributed:
  is_distributed: 0
  cluster:
    ps: ['10.172.110.162:3333']
    chief: ['10.120.180.212:3333']
    worker: ['10.120.180.213:3333', '10.120.180.213:3333', '10.120.180.214:3333', '10.120.180.215:3333']
  job_name: ps
  task_index: 0









